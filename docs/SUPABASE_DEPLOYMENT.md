# ğŸš€ DÃ©ploiement Supabase Edge Functions

## ğŸ¯ Pourquoi Supabase Edge Functions ?

âœ… **Serverless** : Pas de serveur Ã  gÃ©rer
âœ… **Auto-scaling** : S'adapte automatiquement
âœ… **Cron intÃ©grÃ©** : ExÃ©cution programmÃ©e native
âœ… **Gratuit** : Jusqu'Ã  2 millions d'invocations/mois
âœ… **Rapide** : DÃ©ploiement en 2 minutes

---

## ğŸš€ DÃ©ploiement Rapide (2 minutes)

### 1ï¸âƒ£ Installer Supabase CLI

```bash
npm install -g supabase
```

### 2ï¸âƒ£ Login

```bash
supabase login
```

Une fenÃªtre de navigateur s'ouvrira pour vous connecter.

### 3ï¸âƒ£ Link au Projet

```bash
cd /Users/hacker/Desktop/github/github-security-scraper
supabase link --project-ref nykctocknzbstdqnfkun
```

Entrez votre **database password** quand demandÃ©.

### 4ï¸âƒ£ Configurer les Secrets

```bash
# GitHub Token
supabase secrets set GITHUB_TOKEN=ghp_votre_token_ici

# Telegram (si configurÃ©)
supabase secrets set TELEGRAM_BOT_TOKEN=123456789:ABC...
supabase secrets set TELEGRAM_CHAT_ID=-1001234567890
supabase secrets set TELEGRAM_NOTIFICATIONS=true
```

### 5ï¸âƒ£ DÃ©ployer l'Edge Function

```bash
supabase functions deploy scraper-worker
```

Vous devriez voir :
```
Deploying scraper-worker...
âœ“ Function deployed successfully
Function URL: https://nykctocknzbstdqnfkun.supabase.co/functions/v1/scraper-worker
```

---

## â° Configuration du Cron Job

### MÃ©thode 1 : Via SQL (RecommandÃ©)

Dans le **SQL Editor** de Supabase :

```sql
-- Installer l'extension pg_cron (si pas dÃ©jÃ  fait)
CREATE EXTENSION IF NOT EXISTS pg_cron;

-- CrÃ©er le cron job : toutes les 15 minutes
SELECT cron.schedule(
  'github-security-scraper-15min',
  '*/15 * * * *',
  $$
  SELECT
    net.http_post(
      url := 'https://nykctocknzbstdqnfkun.supabase.co/functions/v1/scraper-worker',
      headers := jsonb_build_object(
        'Content-Type', 'application/json',
        'Authorization', 'Bearer ' || current_setting('app.settings.service_role_key')
      ),
      body := '{}'::jsonb
    );
  $$
);
```

### MÃ©thode 2 : Via Dashboard

1. Aller sur https://supabase.com/dashboard/project/nykctocknzbstdqnfkun
2. Database â†’ Cron Jobs
3. Create a new job :
   - **Name** : `github-security-scraper`
   - **Schedule** : `*/15 * * * *` (toutes les 15 min)
   - **Command** : Voir SQL ci-dessus

---

## ğŸ” VÃ©rifier les Cron Jobs

### Lister les jobs actifs

```sql
SELECT 
  jobid,
  schedule,
  command,
  active,
  jobname
FROM cron.job
WHERE jobname LIKE '%github%';
```

### Voir l'historique d'exÃ©cution

```sql
SELECT 
  runid,
  jobid,
  start_time,
  end_time,
  status,
  return_message
FROM cron.job_run_details
WHERE jobid = (SELECT jobid FROM cron.job WHERE jobname = 'github-security-scraper-15min')
ORDER BY start_time DESC
LIMIT 10;
```

### DÃ©sactiver temporairement

```sql
UPDATE cron.job
SET active = false
WHERE jobname = 'github-security-scraper-15min';
```

### RÃ©activer

```sql
UPDATE cron.job
SET active = true
WHERE jobname = 'github-security-scraper-15min';
```

---

## ğŸ“Š Monitoring

### Logs de l'Edge Function

Dans le dashboard Supabase :
1. **Edge Functions** â†’ `scraper-worker`
2. **Logs** tab
3. Voir les exÃ©cutions en temps rÃ©el

### Invocations

```sql
-- Voir les statistiques d'invocation
SELECT 
  DATE_TRUNC('hour', timestamp) as hour,
  COUNT(*) as invocations,
  AVG(execution_time_ms) as avg_time_ms
FROM edge_functions_logs
WHERE function_name = 'scraper-worker'
GROUP BY hour
ORDER BY hour DESC
LIMIT 24;
```

---

## ğŸ§ª Test Manuel

### Via curl

```bash
curl -X POST \
  'https://nykctocknzbstdqnfkun.supabase.co/functions/v1/scraper-worker' \
  -H 'Authorization: Bearer YOUR_ANON_KEY' \
  -H 'Content-Type: application/json' \
  -d '{}'
```

### Via Dashboard

1. Edge Functions â†’ `scraper-worker`
2. **Invoke function** button
3. Body : `{}`
4. Run

Vous devriez recevoir :
```json
{
  "success": true,
  "scanId": "abc-123",
  "totalResults": 42,
  "findingsCount": 5,
  "message": "Scan completed successfully"
}
```

---

## ğŸ”§ Mise Ã  Jour de la Function

### Modifier le code

```bash
# Ã‰diter le fichier
nano supabase/functions/scraper-worker/index.ts

# RedÃ©ployer
supabase functions deploy scraper-worker
```

Railway dÃ©tecte automatiquement les changements !

---

## ğŸ’° CoÃ»ts Supabase

### Plan Gratuit

```
âœ… 2 millions d'invocations/mois
âœ… 500,000 invocations Edge Functions
âœ… 1GB de stockage
âœ… Parfait pour ce scraper
```

**Avec un scan toutes les 15 min :**
```
60/15 = 4 scans/heure
4 x 24 = 96 scans/jour
96 x 30 = 2,880 scans/mois

âœ… Largement dans la limite gratuite !
```

### Plan Pro ($25/mois)

Seulement si vous avez besoin de :
- Plus d'invocations
- Support prioritaire
- Analytics avancÃ©s

**Pour ce scraper : Plan gratuit suffisant ! ğŸ’°**

---

## ğŸ¯ Configurations Multiples

### Option 1 : Edge Function UNIQUEMENT

```
âœ… Serverless
âœ… Gratuit
âœ… Auto-scale
âš ï¸ Cold starts (~1-2s)
```

**RecommandÃ© pour :** Tests, petits volumes

### Option 2 : Railway UNIQUEMENT

```
âœ… Always warm
âœ… Logs riches
âœ… ContrÃ´le total
âš ï¸ CoÃ»t : $5-10/mois
```

**RecommandÃ© pour :** Production, gros volumes

### Option 3 : Les DEUX (Redondance)

```
âœ… Maximum uptime
âœ… Backup automatique
âœ… Load balancing
âš ï¸ CoÃ»t : $5-10/mois
```

**Configuration :**
- **Railway** : Scan toutes les 15 min
- **Supabase** : Scan toutes les 30 min (backup)

**RecommandÃ© pour :** Production critique

---

## ğŸ”’ SÃ©curitÃ©

### Secrets Management

```bash
# Lister les secrets
supabase secrets list

# Supprimer un secret
supabase secrets unset SECRET_NAME

# Mettre Ã  jour un secret
supabase secrets set SECRET_NAME=new_value
```

### AccÃ¨s Ã  la Function

Par dÃ©faut, l'Edge Function est **publique** mais nÃ©cessite l'Anon Key.

Pour restreindre :

```typescript
// VÃ©rifier l'authentification
const authHeader = req.headers.get('authorization');
if (!authHeader || !authHeader.startsWith('Bearer ')) {
  return new Response('Unauthorized', { status: 401 });
}
```

---

## ğŸ› Troubleshooting

### "Function not found"

```bash
# VÃ©rifier que la function est dÃ©ployÃ©e
supabase functions list
```

### "Secret not found"

```bash
# VÃ©rifier les secrets
supabase secrets list

# Ajouter le secret manquant
supabase secrets set GITHUB_TOKEN=ghp_xxx
```

### "Cold start timeout"

Les cold starts peuvent prendre 1-2 secondes.
â†’ Normal pour une Edge Function serverless

### "Out of memory"

Edge Functions ont 150MB de RAM par dÃ©faut.
â†’ RÃ©duire `MAX_RESULTS_PER_SCAN` Ã  50 ou moins

---

## ğŸ“Š Monitoring AvancÃ©

### Voir les erreurs

```sql
SELECT 
  timestamp,
  status_code,
  error_message,
  execution_time_ms
FROM edge_functions_logs
WHERE function_name = 'scraper-worker'
  AND status_code >= 400
ORDER BY timestamp DESC
LIMIT 20;
```

### Alertes sur Ã©checs

```sql
-- CrÃ©er une function qui envoie une alerte si trop d'Ã©checs
CREATE OR REPLACE FUNCTION check_scraper_health()
RETURNS void AS $$
DECLARE
  failure_count INTEGER;
BEGIN
  SELECT COUNT(*) INTO failure_count
  FROM edge_functions_logs
  WHERE function_name = 'scraper-worker'
    AND status_code >= 400
    AND timestamp > now() - interval '1 hour';
  
  IF failure_count > 3 THEN
    -- Envoyer une alerte (via webhook ou autre)
    PERFORM net.http_post(
      url := 'YOUR_WEBHOOK_URL',
      body := jsonb_build_object(
        'alert', 'Scraper failing',
        'failures', failure_count
      )
    );
  END IF;
END;
$$ LANGUAGE plpgsql;

-- ExÃ©cuter toutes les heures
SELECT cron.schedule(
  'check-scraper-health',
  '0 * * * *',
  'SELECT check_scraper_health();'
);
```

---

## ğŸ¯ StratÃ©gies de DÃ©ploiement

### DÃ©veloppement

```bash
# Test local
supabase functions serve scraper-worker --env-file .env

# Test dans le navigateur
open http://localhost:54321/functions/v1/scraper-worker
```

### Staging

```bash
# DÃ©ployer sur un projet de staging
supabase link --project-ref your-staging-project
supabase functions deploy scraper-worker
```

### Production

```bash
# DÃ©ployer sur production
supabase link --project-ref nykctocknzbstdqnfkun
supabase functions deploy scraper-worker
```

---

## ğŸ“š Ressources

- **Supabase Edge Functions** : https://supabase.com/docs/guides/functions
- **pg_cron** : https://github.com/citusdata/pg_cron
- **Deno Deploy** : https://deno.com/deploy

---

## âœ… Checklist de DÃ©ploiement

- [ ] Supabase CLI installÃ©
- [ ] Login rÃ©ussi
- [ ] Projet linkÃ© (`nykctocknzbstdqnfkun`)
- [ ] Secrets configurÃ©s (GITHUB_TOKEN, TELEGRAM_*)
- [ ] Edge Function dÃ©ployÃ©e
- [ ] Cron job crÃ©Ã© (toutes les 15 min)
- [ ] Test manuel rÃ©ussi
- [ ] Notification Telegram reÃ§ue
- [ ] Logs consultÃ©s dans dashboard

---

## ğŸ‰ RÃ©sultat Final

Une fois dÃ©ployÃ© :

âœ… **Serverless** : Aucun serveur Ã  gÃ©rer
âœ… **Auto-scale** : S'adapte Ã  la charge
âœ… **Cron SQL** : ExÃ©cution toutes les 15 min
âœ… **Telegram** : Notifications temps rÃ©el
âœ… **Gratuit** : Plan gratuit suffisant

**Temps de dÃ©ploiement : 2 minutes** â±ï¸
**CoÃ»t : $0/mois** (plan gratuit) ğŸ’°

---

**Prochaine Ã©tape : DÃ©ployer !**

```bash
supabase functions deploy scraper-worker
```

Version 3.0 - Supabase Ready
Octobre 2025
